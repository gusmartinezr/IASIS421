{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SegundoParcial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/gusmartinezr/IASIS421/tree/main/Examen/Examen%20Final"
      ],
      "metadata": {
        "id": "odjFlzWLOA6O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pElCCA7gcVq",
        "outputId": "85d71072-c75f-473c-a6c1-fc1825e3e7cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/drive/MyDrive/IA2/ApodosIngles.txt\", \"r\", encoding='utf-8')\n",
        "text = f.read()\n",
        "text[:300], len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9sutS20geK6",
        "outputId": "ffcf9ebd-922b-480b-fc24-ad703c1719ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Aaron\\tRon RonnE Erin\\tRonald\\nAbel\\tAbe Ab Eb EbbE\\nAbiel\\tBiel Ab\\nAbigail\\tAb AbbE Gail NabbE\\tTabitha\\nAbijah\\tAb Bige Abiah Ab Biah\\nAbner\\tAb AbbE\\nAbraham\\tAbe Abram\\nAbsalom\\tAb AbbE\\nAdaline\\tAda Adela Aline Edith AddE Dell Delia Lena\\tAdelaide\\nAdam\\tAde EdE Ad\\nAdelaide\\tAddE Adela Adaline Adeline Della Heide Ad',\n",
              " 16755)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenización"
      ],
      "metadata": {
        "id": "q_QEeO7-hKlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "all_characters = string.printable\n",
        "all_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ivnQEM5qg-Kz",
        "outputId": "f8887970-682c-4d94-e244-2adc4dad55fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "class Tokenizer(): \n",
        "    \n",
        "  def __init__(self):\n",
        "    self.all_characters = all_characters\n",
        "    self.n_characters = len(self.all_characters)\n",
        "    \n",
        "  def text_to_seq(self, string):\n",
        "    seq = []\n",
        "    for c in range(len(string)):\n",
        "        try:\n",
        "            seq.append(self.all_characters.index(string[c]))\n",
        "        except:\n",
        "            continue\n",
        "    return seq\n",
        "\n",
        "  def seq_to_text(self, seq):\n",
        "    text = ''\n",
        "    for c in range(len(seq)):\n",
        "        text += self.all_characters[seq[c]]\n",
        "    return text\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.n_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE3Ll9DthOsn",
        "outputId": "bff2a64a-ec40-4b4d-9fbc-fe0ba4bec4c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.text_to_seq('Aaron')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uVpwuV8hV57",
        "outputId": "9db0285d-3960-45dc-fbde-374ef46aa2eb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36, 10, 27, 24, 23]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.seq_to_text([36, 10, 27, 24, 23])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v_n-kYa2hi7s",
        "outputId": "2010e75f-6de4-4b14-97f8-790ec218d9dd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Aaron'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoded = tokenizer.text_to_seq(text)"
      ],
      "metadata": {
        "id": "v12lmxJrhu3i"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(text_encoded) * 80 // 100 \n",
        "train = text_encoded[:train_size]\n",
        "test = text_encoded[train_size:]\n",
        "\n",
        "len(train), len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys94jR9kh0YA",
        "outputId": "f04c899c-b461-4ab6-dadf-b93a02e05994"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13404, 3351)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def windows(text, window_size = 100):\n",
        "    start_index = 0\n",
        "    end_index = len(text) - window_size\n",
        "    text_windows = []\n",
        "    while start_index < end_index:\n",
        "      text_windows.append(text[start_index:start_index+window_size+1])\n",
        "      start_index += 1\n",
        "    return text_windows\n",
        "\n",
        "text_encoded_windows = windows(text_encoded)"
      ],
      "metadata": {
        "id": "s9P6P0zziCVX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.seq_to_text((text_encoded_windows[0])))\n",
        "print()\n",
        "print(tokenizer.seq_to_text((text_encoded_windows[1])))\n",
        "print()\n",
        "print(tokenizer.seq_to_text((text_encoded_windows[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pp95JOUiOMT",
        "outputId": "edb4a48e-0a1f-41ab-f7de-30b01b81547a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aaron\tRon RonnE Erin\tRonald\n",
            "Abel\tAbe Ab Eb EbbE\n",
            "Abiel\tBiel Ab\n",
            "Abigail\tAb AbbE Gail NabbE\tTabitha\n",
            "Abij\n",
            "\n",
            "aron\tRon RonnE Erin\tRonald\n",
            "Abel\tAbe Ab Eb EbbE\n",
            "Abiel\tBiel Ab\n",
            "Abigail\tAb AbbE Gail NabbE\tTabitha\n",
            "Abija\n",
            "\n",
            "ron\tRon RonnE Erin\tRonald\n",
            "Abel\tAbe Ab Eb EbbE\n",
            "Abiel\tBiel Ab\n",
            "Abigail\tAb AbbE Gail NabbE\tTabitha\n",
            "Abijah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class CharRNNDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, text_encoded_windows, train=True):\n",
        "    self.text = text_encoded_windows\n",
        "    self.train = train\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "\n",
        "  def __getitem__(self, ix):\n",
        "    if self.train:\n",
        "      return torch.tensor(self.text[ix][:-1]), torch.tensor(self.text[ix][-1])\n",
        "    return torch.tensor(self.text[ix])"
      ],
      "metadata": {
        "id": "u6PDS7bCiSf1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_encoded_windows = windows(train)\n",
        "test_text_encoded_windows = windows(test)\n",
        "\n",
        "dataset = {\n",
        "    'train': CharRNNDataset(train_text_encoded_windows),\n",
        "    'val': CharRNNDataset(test_text_encoded_windows)\n",
        "}\n",
        "\n",
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True, pin_memory=True),\n",
        "    'val': torch.utils.data.DataLoader(dataset['val'], batch_size=50, shuffle=False, pin_memory=True),\n",
        "}\n",
        "\n",
        "len(dataset['train']), len(dataset['val'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP14AhEjigON",
        "outputId": "3d85c42f-a9a4-4be0-e377-bb0b58cf7f10"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13304, 3251)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input, output = dataset['train'][1]\n",
        "tokenizer.seq_to_text(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s0FKI5h6ilSZ",
        "outputId": "27cd011c-6d6d-434b-d316-49336c0e211f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aron\\tRon RonnE Erin\\tRonald\\nAbel\\tAbe Ab Eb EbbE\\nAbiel\\tBiel Ab\\nAbigail\\tAb AbbE Gail NabbE\\tTabitha\\nAbij'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.seq_to_text([output])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "siCxGwjOioJ6",
        "outputId": "a0377bdc-c701-43f4-c488-8882f4bb04f0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(torch.nn.Module):\n",
        "  def __init__(self, input_size, embedding_size=100, hidden_size=400, num_layers=2, dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.encoder = torch.nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = torch.nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "    self.fc = torch.nn.Linear(hidden_size, input_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x, h = self.rnn(x)         \n",
        "    y = self.fc(x[:,-1,:])\n",
        "    return y"
      ],
      "metadata": {
        "id": "EJTtEws0isUZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iGU_ZH5eN_1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CharRNN(input_size=tokenizer.n_characters)\n",
        "outputs = model(torch.randint(0, tokenizer.n_characters, (64, 50)))\n",
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW-oI3vmivcq",
        "outputId": "6470d51a-0474-4ca3-b769-a624c312140a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def fit(model, dataloader, epochs=10):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f}\")\n",
        "        bar = tqdm(dataloader['val'])\n",
        "        val_loss = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f}\")\n",
        "\n",
        "def predict(model, X):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X).to(device)\n",
        "        pred = model(X.unsqueeze(0))\n",
        "        return pred"
      ],
      "metadata": {
        "id": "xeRZfzEiixMs"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CharRNN(input_size=tokenizer.n_characters)\n",
        "fit(model, dataloader, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7shauBY4iz-T",
        "outputId": "5313e5bc-c5f5-45d3-debd-c5c5948f69a8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 2.90289: 100%|██████████| 208/208 [00:08<00:00, 25.28it/s]\n",
            "val_loss 2.76481: 100%|██████████| 66/66 [00:00<00:00, 76.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 loss 2.90289 val_loss 2.76481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 2.31379: 100%|██████████| 208/208 [00:08<00:00, 24.84it/s]\n",
            "val_loss 2.57677: 100%|██████████| 66/66 [00:00<00:00, 77.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 loss 2.31379 val_loss 2.57677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 2.11490: 100%|██████████| 208/208 [00:08<00:00, 24.67it/s]\n",
            "val_loss 2.52870: 100%|██████████| 66/66 [00:00<00:00, 74.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 loss 2.11490 val_loss 2.52870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 1.92010: 100%|██████████| 208/208 [00:08<00:00, 24.61it/s]\n",
            "val_loss 2.48390: 100%|██████████| 66/66 [00:00<00:00, 73.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20 loss 1.92010 val_loss 2.48390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 1.70508: 100%|██████████| 208/208 [00:08<00:00, 24.59it/s]\n",
            "val_loss 2.38724: 100%|██████████| 66/66 [00:00<00:00, 76.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20 loss 1.70508 val_loss 2.38724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 1.47483: 100%|██████████| 208/208 [00:08<00:00, 24.65it/s]\n",
            "val_loss 2.39007: 100%|██████████| 66/66 [00:00<00:00, 74.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20 loss 1.47483 val_loss 2.39007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 1.26847: 100%|██████████| 208/208 [00:08<00:00, 24.63it/s]\n",
            "val_loss 2.35727: 100%|██████████| 66/66 [00:00<00:00, 76.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 loss 1.26847 val_loss 2.35727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 1.08625: 100%|██████████| 208/208 [00:08<00:00, 24.67it/s]\n",
            "val_loss 2.42300: 100%|██████████| 66/66 [00:00<00:00, 75.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 loss 1.08625 val_loss 2.42300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.92116: 100%|██████████| 208/208 [00:08<00:00, 24.63it/s]\n",
            "val_loss 2.49605: 100%|██████████| 66/66 [00:00<00:00, 75.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 loss 0.92116 val_loss 2.49605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.77765: 100%|██████████| 208/208 [00:08<00:00, 24.68it/s]\n",
            "val_loss 2.61106: 100%|██████████| 66/66 [00:00<00:00, 76.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 loss 0.77765 val_loss 2.61106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.64318: 100%|██████████| 208/208 [00:08<00:00, 24.67it/s]\n",
            "val_loss 2.75976: 100%|██████████| 66/66 [00:00<00:00, 75.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 loss 0.64318 val_loss 2.75976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.52826: 100%|██████████| 208/208 [00:08<00:00, 24.64it/s]\n",
            "val_loss 2.92262: 100%|██████████| 66/66 [00:00<00:00, 75.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 loss 0.52826 val_loss 2.92262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.42824: 100%|██████████| 208/208 [00:08<00:00, 24.64it/s]\n",
            "val_loss 2.97377: 100%|██████████| 66/66 [00:00<00:00, 75.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20 loss 0.42824 val_loss 2.97377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.36144: 100%|██████████| 208/208 [00:08<00:00, 24.68it/s]\n",
            "val_loss 3.17288: 100%|██████████| 66/66 [00:00<00:00, 73.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20 loss 0.36144 val_loss 3.17288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.29470: 100%|██████████| 208/208 [00:08<00:00, 24.63it/s]\n",
            "val_loss 3.34154: 100%|██████████| 66/66 [00:00<00:00, 76.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20 loss 0.29470 val_loss 3.34154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.23442: 100%|██████████| 208/208 [00:08<00:00, 24.68it/s]\n",
            "val_loss 3.47715: 100%|██████████| 66/66 [00:00<00:00, 74.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20 loss 0.23442 val_loss 3.47715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.19728: 100%|██████████| 208/208 [00:08<00:00, 24.68it/s]\n",
            "val_loss 3.49835: 100%|██████████| 66/66 [00:00<00:00, 75.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20 loss 0.19728 val_loss 3.49835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.16269: 100%|██████████| 208/208 [00:08<00:00, 24.60it/s]\n",
            "val_loss 3.58990: 100%|██████████| 66/66 [00:00<00:00, 75.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 loss 0.16269 val_loss 3.58990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.13581: 100%|██████████| 208/208 [00:08<00:00, 24.58it/s]\n",
            "val_loss 3.71683: 100%|██████████| 66/66 [00:00<00:00, 75.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 loss 0.13581 val_loss 3.71683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.11558: 100%|██████████| 208/208 [00:08<00:00, 24.62it/s]\n",
            "val_loss 3.94583: 100%|██████████| 66/66 [00:00<00:00, 76.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20 loss 0.11558 val_loss 3.94583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = \"Arthur\"\n",
        "X_new_encoded = tokenizer.text_to_seq(X_new)\n",
        "y_pred = predict(model, X_new_encoded)\n",
        "y_pred = torch.argmax(y_pred, axis=1)[0].item()\n",
        "tokenizer.seq_to_text([y_pred])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Uqz44YVyi2OD",
        "outputId": "6dc1e518-04af-489f-e493-803bfd94fbe0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "  X_new_encoded = tokenizer.text_to_seq(X_new[-100:])\n",
        "  y_pred = predict(model, X_new_encoded)\n",
        "  y_pred = torch.argmax(y_pred, axis=1)[0].item()\n",
        "  X_new += tokenizer.seq_to_text([y_pred])\n",
        "\n",
        "X_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YlP4bafbjLnr",
        "outputId": "7d7f9ec4-76b9-431a-ebf4-346c6ff20956"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Arthur\\nArt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=1\n",
        "for i in range(100):\n",
        "  X_new_encoded = tokenizer.text_to_seq(X_new[-100:])\n",
        "  y_pred = predict(model, X_new_encoded)\n",
        "  y_pred = y_pred.view(-1).div(temp).exp()\n",
        "  top_i = torch.multinomial(y_pred, 1)[0]\n",
        "  predicted_char = tokenizer.all_characters[top_i]\n",
        "  X_new += predicted_char\n",
        "\n",
        "print(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmYzqwmpjN4e",
        "outputId": "eff84afa-5298-4547-8daa-eed4f430897d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arthur\n",
            "Arthene\tArnE HerrE Dena\n",
            "Ardolia\tAllE BaldE\n",
            "Arminda\tBindE ArcE\n",
            "Arminda\tMindE\n",
            "Arminda\tMindE MindE\n",
            "Arminda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ExHHoJi33cAa"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}